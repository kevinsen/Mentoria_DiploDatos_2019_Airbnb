{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn, sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "sns.set_style('whitegrid')\n",
    "##%matplotlib inline\n",
    "\n",
    "#### import the data\n",
    "train_users   = pd.read_csv('../Datos/train_users_2.csv')\n",
    "test_users    = pd.read_csv('../Datos/test_users.csv')\n",
    "gender = pd.read_csv('../input/age_gender_bkts.csv')\n",
    "sessions = pd.read_csv('../input/sessions.csv')\n",
    "countries = pd.read_csv('../input/countries.csv')\n",
    "\n",
    "##all_users = pd.concat((train_users, test_users), axis=0, ignore_index=True)\n",
    "\n",
    "mobile_browsers = []\n",
    "for x in train_users['first_browser'].unique():\n",
    "    if 'Mobile' in x:\n",
    "        mobile_browsers.append(x)\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "major_browsers = ['IE', 'Safari', '-unknown- ', 'Chrome', 'Firefox', 'Mobile']  \n",
    "\n",
    "### group up those first_browsers\n",
    "train_users['first_browser_grouped'] = np.where(train_users['first_browser'].isin(mobile_browsers), 'Mobile', train_users['first_browser'])\n",
    "train_users['first_browser_grouped'] = np.where(train_users['first_browser_grouped'].isin(major_browsers), train_users['first_browser_grouped'], 'Other')\n",
    "\n",
    "### find year of account creation\n",
    "#train_users['year_account_creation'] = pd.DatetimeIndex(train_users['date_account_created']).year\n",
    "\n",
    "### group up the first_device_type\n",
    "dict_first_device_type = {\"Mac Desktop\": \"Desktop\",\n",
    "                          \"Windows Desktop\": \"Desktop\",\n",
    "                          \"Desktop (Other)\": \"Desktop\",\n",
    "                          \"iPhone\": \"Phone/Pad\",\n",
    "                          \"iPad\": \"Phone/Pad\",\n",
    "                          \"Android Tablet\": \"Phone/Pad\", \n",
    "                          \"Android Phone\": \"Phone/Pad\",\n",
    "                          \"SmartPhone (Other)\": \"Phone/Pad\"}\n",
    "train_users = train_users.replace({\"first_device_type\": dict_first_device_type})\n",
    "\n",
    "\n",
    "\n",
    "######### apply the above adjustments to the test dataset\n",
    "test_users['first_browser_grouped'] = np.where(test_users['first_browser'].isin(mobile_browsers), 'Mobile', test_users['first_browser'])\n",
    "test_users['first_browser_grouped'] = np.where(test_users['first_browser_grouped'].isin(major_browsers), test_users['first_browser_grouped'], 'Other')\n",
    "#test_users['year_account_creation'] = pd.DatetimeIndex(test_users['date_account_created']).year\n",
    "test_users = test_users.replace({\"first_device_type\": dict_first_device_type})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "language_distance = {'language' : ['en', 'du', 'fr', 'es'],\n",
    "                     'levenshtein_distance_from_en' : [0, 72.61, 92.06, 92.25]}\n",
    "\n",
    "language_distance = pd.DataFrame(language_distance)\n",
    "\n",
    "train_users = pd.merge(train_users, language_distance, on = 'language', how = 'left')\n",
    "test_users = pd.merge(test_users, language_distance, on = 'language', how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########## fill in the missing values\n",
    "train_users['levenshtein_distance_from_en'].fillna(-1)\n",
    "test_users['levenshtein_distance_from_en'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##train_users['year_account_creation'] = pd.DatetimeIndex(train_users['date_account_created']).year\n",
    "train_users['timestamp_first_active'] = train_users['timestamp_first_active'].astype(str)\n",
    "\n",
    "train_users['date_account_created'] = pd.to_datetime(train_users['date_account_created'])\n",
    "\n",
    "#### converting the first active day to a date-time var\n",
    "train_users['timestamp_first_active_day'] = train_users['timestamp_first_active'].str[:8]\n",
    "train_users['timestamp_first_active_day'] = pd.to_datetime(train_users['timestamp_first_active_day'], format='%Y%m%d')\n",
    "\n",
    "#### find the first active year\n",
    "train_users['timestamp_first_active_year'] = train_users['timestamp_first_active'].str[:4]\n",
    "train_users['timestamp_first_active_hour'] = train_users['timestamp_first_active'].str[8:10]\n",
    "\n",
    "#### create a var to see if they searched before joining\n",
    "#train_users['searched_before_joining'] = (train_users['timestamp_first_active_day'] < train_users['date_account_created'])\n",
    "#train_users['searched_before_joining'] = train_users['searched_before_joining'] * 1\n",
    "\n",
    "#### did they do a previous trip? This appears to be a weird variable..\n",
    "##train_users['first_trip'] = pd.isnull(train_users['date_first_booking']) * 1\n",
    "\n",
    "major_languages = ['en']  \n",
    "train_users['language_bucket'] = np.where(train_users['language'].isin(major_languages), 'en', 'other')\n",
    "\n",
    "##### group up the age variable\n",
    "labels = [1, 2, 3, 4, 5, 6, 7]\n",
    "bins = [0, 20, 30, 40, 50, 60, 9000, 100000]\n",
    "train_users['age'].fillna(10000)\n",
    "train_users['age_group'] = pd.cut(train_users['age'], bins, right=False, labels=labels)\n",
    "train_users['age_group'] = train_users['age_group'] * 1\n",
    "\n",
    "train_users[\"signup_combo\"] = train_users[\"signup_method\"].map(str) + train_users[\"signup_flow\"].map(str)\n",
    "\n",
    "##### let's group the affiliate_provider variable\n",
    "\n",
    "major_affiliate_providers = ['direct', 'google', 'bing', 'craigslist', 'facebook']\n",
    "train_users['affiliate_provider_grp'] = np.where(train_users['affiliate_provider'].isin(major_affiliate_providers), train_users['affiliate_provider'], 'other')\n",
    "train_users[\"affiliate_combined\"] = train_users[\"affiliate_provider_grp\"].map(str) + train_users[\"affiliate_channel\"].map(str)\n",
    "\n",
    "\n",
    "###### adjust test so it matches the adjustments made to the train dataset\n",
    "test_users['timestamp_first_active'] = test_users['timestamp_first_active'].astype(str)\n",
    "test_users['date_account_created'] = pd.to_datetime(test_users['date_account_created'])\n",
    "test_users['timestamp_first_active_day'] = test_users['timestamp_first_active'].str[:8]\n",
    "test_users['timestamp_first_active_day'] = pd.to_datetime(test_users['timestamp_first_active_day'], format='%Y%m%d')\n",
    "test_users['timestamp_first_active_year'] = test_users['timestamp_first_active'].str[:4]\n",
    "#test_users['searched_before_joining'] = (test_users['timestamp_first_active_day'] < test_users['date_account_created'])\n",
    "#test_users['searched_before_joining'] = test_users['searched_before_joining'] * 1\n",
    "##test_users['first_trip'] = pd.isnull(test_users['date_first_booking']) * 1\n",
    "test_users['language_bucket'] = np.where(test_users['language'].isin(major_languages), 'en', 'other')\n",
    "test_users['age'].fillna(10000)\n",
    "test_users['age_group'] = pd.cut(test_users['age'], bins, right=False, labels=labels)\n",
    "test_users['age_group'] = test_users['age_group'] * 1\n",
    "test_users['timestamp_first_active_day'] = pd.to_datetime(test_users['timestamp_first_active_day'], format='%Y%m%d')\n",
    "test_users[\"signup_combo\"] = test_users[\"signup_method\"].map(str) + test_users[\"signup_flow\"].map(str)\n",
    "test_users['timestamp_first_active_hour'] = test_users['timestamp_first_active'].str[8:10]\n",
    "test_users['affiliate_provider_grp'] = np.where(test_users['affiliate_provider'].isin(major_affiliate_providers), test_users['affiliate_provider'], 'other')\n",
    "test_users[\"affiliate_combined\"] = test_users[\"affiliate_provider_grp\"].map(str) + test_users[\"affiliate_channel\"].map(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##train_users.head()\n",
    "##train_users[train_users['first_browser_grouped'] == 'Mobile']\n",
    "\n",
    "#### language doesn't appear that helpful.. anyway we can adjust it some?\n",
    "\n",
    "#train_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#test = [0]\n",
    "#train_users['tester'] = np.where((train_users['timestamp_first_active_day'] - train_users['date_account_created']).isin(test), 0, 1)\n",
    "\n",
    "#fig, (axis1) = plt.subplots(1,1,figsize=(15,5))\n",
    "#fig, (axis1, axis2, axis3) = plt.subplots(3,1,figsize=(15,15))\n",
    "#sns.countplot(x='language_bucket', hue = 'country_destination', data=train_users, palette=\"husl\", ax=axis1)\n",
    "#sns.countplot(x = 'affiliate_channel', hue = 'country_destination', data = train_users, palette = 'husl', ax = axis2)\n",
    "#sns.countplot(x = 'affiliate_provider_grp', hue = 'country_destination', data = train_users, palette = 'husl', ax = axis3)\n",
    "#sns.countplot(x = 'signup_app', hue = 'country_destination', data = train_users, palette = 'husl', ax = axis4)\n",
    "#sns.countplot(x = 'affiliate_provider', hue = 'country_destination', data = train_users[train_users['affiliate_provider'] != 'direct'], palette = 'husl', ax = axis5)\n",
    "#sns.countplot(x = 'tester', hue = 'country_destination', data = train_users[train_users['tester'] == 1], palette = 'husl', ax = axis1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig, (axis1, axis2) = plt.subplots(2,1,figsize=(15,10))\n",
    "#sns.countplot(x='affiliate_channel', hue = 'country_destination', data=train_users[train_users['affiliate_provider_grp'] == 'google'], palette=\"husl\", ax=axis1)\n",
    "#sns.countplot(x='affiliate_provider_grp', hue = 'country_destination', data=train_users[train_users['affiliate_channel'] == 'seo'], palette=\"husl\", ax=axis2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### I'm curious, what's the interaction between date_account_created and timestamp_first_active? \n",
    "#train_users['date_account_created'] = pd.to_datetime(train_users['date_account_created'])\n",
    "#train_users['dif_btwn_creation_and_search'] = (train_users['timestamp_first_active_day'] - train_users['date_account_created']).astype('timedelta64[M]')\n",
    "#train_users['dif_btwn_creation_and_search_rounded'] = train_users['dif_btwn_creation_and_search'].round(-1)\n",
    "\n",
    "\n",
    "#fig, (axis1) = plt.subplots(1,1,figsize=(15,5))\n",
    "#sns.countplot(x='dif_btwn_creation_and_search_rounded', hue = 'country_destination', data=train_users, palette=\"husl\", ax=axis1)\n",
    "\n",
    "#train_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#fig, (axis1) = plt.subplots(1,1,figsize=(15,5))\n",
    "#sns.countplot(x='age_group', hue = 'country_destination', data=train_users, palette=\"husl\", ax=axis1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### is it worthwhile to group up some of these X vars w/ a lot of subclasses? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######\n",
    "\n",
    "train_users['month_created'] = train_users['date_account_created'].map(lambda x: x.month)\n",
    "train_users['year_created'] = train_users['date_account_created'].map(lambda x: x.year)\n",
    "train_users['month_year_created'] = train_users['date_account_created'].map(lambda x: x.year * 1000 + x.month)\n",
    "\n",
    "train_users['month_first_active'] = train_users['timestamp_first_active_day'].map(lambda x: x.month)\n",
    "train_users['year_first_active'] = train_users['timestamp_first_active_day'].map(lambda x: x.year)\n",
    "train_users['month_year_first_active'] = train_users['timestamp_first_active_day'].map(lambda x: x.year * 1000 + x.month)\n",
    "\n",
    "########\n",
    "test_users['month_created'] = test_users['date_account_created'].map(lambda x: x.month)\n",
    "test_users['year_created'] = test_users['date_account_created'].map(lambda x: x.year)\n",
    "test_users['month_year_created'] = test_users['date_account_created'].map(lambda x: x.year * 1000 + x.month)\n",
    "\n",
    "test_users['month_first_active'] = test_users['timestamp_first_active_day'].map(lambda x: x.month)\n",
    "test_users['year_first_active'] = test_users['timestamp_first_active_day'].map(lambda x: x.year)\n",
    "test_users['month_year_first_active'] = test_users['timestamp_first_active_day'].map(lambda x: x.year * 1000 + x.month)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "train_users = train_users.drop(['date_account_created', 'timestamp_first_active', 'timestamp_first_active_day', 'date_first_booking'], axis = 1)\n",
    "test_users = test_users.drop(['date_account_created', 'timestamp_first_active', 'timestamp_first_active_day', 'date_first_booking'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### this removes the missing values\n",
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "    \n",
    "train_users_imputed = DataFrameImputer().fit_transform(train_users)\n",
    "test_users_imputed = DataFrameImputer().fit_transform(test_users)\n",
    "\n",
    "\n",
    "### this will transfer the categorical variables to floats for the algo\n",
    "def do_treatment(df):\n",
    "    for col in df:\n",
    "        if df[col].dtype == np.dtype('O') and df[col].name != 'id' and df[col].name != 'country_destination' and df[col].name != 'age_group' and df[col].name != 'timestamp_first_active_day':\n",
    "            df[col] = df[col].apply(lambda x : hash(str(x)))\n",
    "\n",
    "    \n",
    "do_treatment(train_users_imputed)\n",
    "do_treatment(test_users_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.any(np.isnan(train_users['id']))\n",
    "#print(np.all(np.isfinite(col)))\n",
    "\n",
    "#np.isnan(train_users.any())\n",
    "#np.isfinite(train_users.any())\n",
    "\n",
    "#np.isnan(test_users.any())\n",
    "#np.isfinite(test_users.any())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train_users.head()\n",
    "\n",
    "\n",
    "X_train = train_users_imputed.drop(['signup_app', 'affiliate_provider', 'affiliate_channel', 'levenshtein_distance_from_en', 'month_year_first_active', 'month_year_created', 'year_first_active', 'timestamp_first_active_year', 'country_destination', 'id', 'first_browser', 'age', 'language'], axis=1)\n",
    "y_train = train_users_imputed['country_destination']\n",
    "X_test = test_users_imputed.drop(['signup_app', 'affiliate_provider', 'affiliate_channel', 'levenshtein_distance_from_en', 'month_year_first_active', 'month_year_created', 'year_first_active', 'timestamp_first_active_year', 'id', 'age', 'first_browser', 'language'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "country_num_dic = {'NDF': 0, 'US': 1, 'other': 2, 'FR': 3, 'IT': 4, 'GB': 5, 'ES': 6, 'CA': 7, 'DE': 8, 'NL': 9, 'AU': 10, 'PT': 11}\n",
    "num_country_dic = {y:x for x,y in country_num_dic.items()}\n",
    "\n",
    "y_train    = y_train.map(country_num_dic)\n",
    "\n",
    "##### build the model\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 200, max_features = 'sqrt',\n",
    "                             max_depth = None, verbose = 1, n_jobs = -1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_probs = clf.predict_proba(X_test) ## prob of being in a certain class\n",
    "test_preds = clf.predict(X_test)\n",
    "test_preds = test_preds.astype(int)\n",
    "\n",
    "# change values back to original country symbols\n",
    "test_preds = Series(test_preds).map(num_country_dic)\n",
    "\n",
    "output = pd.DataFrame(test_users.id).join(pd.DataFrame(clf_probs))\n",
    "output_melted = pd.melt(output, id_vars = 'id')\n",
    "# convert type to integer\n",
    "output_melted['variable'] = output_melted['variable'].astype(int)\n",
    "\n",
    "# change values back to original country symbols\n",
    "output_melted['variable'] = Series(output_melted['variable']).map(num_country_dic)\n",
    "\n",
    "output_sorted = output_melted.sort(['id', 'value'], ascending=[1, 0])\n",
    "top_5_records = output_sorted.groupby('id').head(5)\n",
    "top_5_records_trimmed = top_5_records.drop(['value'], axis = 1)\n",
    "top_5_records_trimmed.columns = ['id', 'country']\n",
    "\n",
    "final_output = DataFrame(columns=['id', 'country'])\n",
    "final_output = final_output.append(top_5_records_trimmed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### get the output ready for a csv submission\n",
    "#output = pd.DataFrame(test_users.id).join(pd.DataFrame(test_preds))\n",
    "#output.columns = ['id', 'country_destination']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "###### look at variable importance in the model \n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in indices:\n",
    "    print(X_train.columns[f], importances[f])\n",
    "    #print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "#for x in range(X_train.shape[1]):\n",
    "#    print(X_train.columns[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### alright, if none of the entries for an id is NDF, then set the 5th obs == NDF\n",
    "no_ndf_ppl = top_5_records[~top_5_records['id'].isin(top_5_records['id'][top_5_records['variable'] == 'NDF'])]\n",
    "ndf_ppl = top_5_records[top_5_records['id'].isin(top_5_records['id'][top_5_records['variable'] == 'NDF'])]\n",
    "\n",
    "no_ndf_ppl_first = no_ndf_ppl.sort(['value'], ascending=[1])\n",
    "no_ndf_ppl_first_ndf = no_ndf_ppl_first.groupby('id').head(1)\n",
    "no_ndf_ppl_first_ndf['variable'] = 'NDF'\n",
    "\n",
    "no_ndf_ppl_first_4 = no_ndf_ppl.sort(['value'], ascending=[0])\n",
    "no_ndf_ppl_first_other = no_ndf_ppl_first_4.groupby('id').head(4)\n",
    "\n",
    "##### combine all of the dataframes together\n",
    "result = pd.concat([no_ndf_ppl_first_ndf, no_ndf_ppl_first_other , ndf_ppl])\n",
    "result = result.drop(['value'], axis = 1)\n",
    "result.columns = ['id', 'country']\n",
    "\n",
    "#### create the final output dataframe\n",
    "final_output_adjusted = DataFrame(columns=['id', 'country'])\n",
    "final_output_adjusted = final_output_adjusted.append(result)\n",
    "\n",
    "#### convert to csv\n",
    "final_output_adjusted.to_csv('adjusted.csv', index = False, header = ['id', 'country'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
